{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read csv (comma separated value) into data\n",
    "train = pd.read_csv('london_scikit_learn/train.csv', header=None)\n",
    "trainLabel = pd.read_csv('london_scikit_learn/trainLabels.csv', header=None)\n",
    "test = pd.read_csv('london_scikit_learn/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1000, 40)\n",
      "test shape: (9000, 40)\n",
      "trainLabel shape: (1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9     ...           30        31        32  \\\n",
       "0  1.594506 -0.051608  0.663234    ...    -0.850465 -0.622990 -1.833057   \n",
       "1  2.619246 -0.765884 -0.093780    ...    -0.819750  0.012037  2.038836   \n",
       "2 -4.219054 -1.184919 -1.240310    ...    -0.604501  0.750054 -3.360521   \n",
       "3  4.499666  1.038741 -1.092716    ...     1.022959  1.275598 -3.480110   \n",
       "4 -4.290282 -1.761308  0.807652    ...     0.513906 -1.803473  0.518579   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0  0.293024  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1  0.468579 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2  0.856988 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3 -1.065252  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -0.205029 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train shape:', train.shape)\n",
    "print('test shape:', test.shape)\n",
    "print('trainLabel shape:', trainLabel.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025596</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024088</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>1.092329</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.497342</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.542491</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.567185</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.892659</td>\n",
       "      <td>0.609451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008282</td>\n",
       "      <td>1.016298</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.970575</td>\n",
       "      <td>4.538834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>2.118819</td>\n",
       "      <td>2.232256</td>\n",
       "      <td>1.001064</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011645</td>\n",
       "      <td>1.001375</td>\n",
       "      <td>2.239939</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>2.121281</td>\n",
       "      <td>1.007044</td>\n",
       "      <td>2.227876</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>2.022022</td>\n",
       "      <td>2.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.379194</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669010</td>\n",
       "      <td>-0.693937</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.617557</td>\n",
       "      <td>-1.801997</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>-1.604037</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659457</td>\n",
       "      <td>-0.696032</td>\n",
       "      <td>-2.121943</td>\n",
       "      <td>-0.664550</td>\n",
       "      <td>-1.879247</td>\n",
       "      <td>-0.642861</td>\n",
       "      <td>-1.059786</td>\n",
       "      <td>-0.691162</td>\n",
       "      <td>-2.220126</td>\n",
       "      <td>-0.565041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.862818</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.036110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>-0.568262</td>\n",
       "      <td>-0.028097</td>\n",
       "      <td>-0.493575</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.855470</td>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762520</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.640743</td>\n",
       "      <td>3.843172</td>\n",
       "      <td>0.671456</td>\n",
       "      <td>1.913664</td>\n",
       "      <td>1.438304</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747031</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>1.005795</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.122157</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.992193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844792</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
       "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
       "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
       "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
       "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
       "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
       "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
       "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
       "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
       "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
       "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
       "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
       "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
       "\n",
       "          ...                30           31           32           33  \\\n",
       "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
       "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
       "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
       "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
       "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
       "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
       "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
       "\n",
       "                34           35           36           37           38  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
       "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
       "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
       "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
       "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
       "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
       "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
       "\n",
       "                39  \n",
       "count  1000.000000  \n",
       "mean      0.609451  \n",
       "std       2.045439  \n",
       "min      -7.799086  \n",
       "25%      -0.565041  \n",
       "50%       0.779944  \n",
       "75%       1.992193  \n",
       "max       6.803984  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "X, y = train, np.ravel(trainLabel)\n",
    "std = StandardScaler()\n",
    "X_std = std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.836666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDACGEMAAYMj/AsooZp9SilTPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160d34e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160d5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split data train 70 % and val 30 %\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_std, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#random forest classifier with n_estimators=10 (default)\n",
    "clf_rf = RandomForestClassifier(random_state=43)      \n",
    "clr_rf = clf_rf.fit(X_train,y_train)\n",
    "\n",
    "ac = accuracy_score(y_val,clf_rf.predict(X_val))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_val,clf_rf.predict(X_val))\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.figure(figsize=[13,8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=0.8, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.84, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.85, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.84, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................................... , score=0.79, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.83, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.86, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.77, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.85, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.78, total=   0.0s\n",
      "best estimator RandomForest: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) Best Score 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest : 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "x_train = train\n",
    "y_train = trainLabel\n",
    "x_test = test\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = dict( )\n",
    "#### GRID SEARCH for BEST TUNING PARAMETERS FOR RandomForest #####\n",
    "grid_search_rf = GridSearchCV(rf, param_grid=dict( ), verbose=3,scoring='accuracy',cv=10).fit(x_train,y_train)\n",
    "print('best estimator RandomForest:',grid_search_rf.best_estimator_,'Best Score', grid_search_rf.best_estimator_.score(x_train,y_train))\n",
    "rf_best = grid_search_rf.best_estimator_\n",
    "rf_best.fit(x_train,y_train)\n",
    "#### SCORING THE MODELS ####\n",
    "print('Score for Random Forest :',cross_val_score(rf_best,x_train,y_train,cv=10,scoring='accuracy').max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  Solution\n",
      "1        1         1\n",
      "2        2         0\n",
      "3        3         0\n",
      "4        4         0\n",
      "5        5         0\n",
      "6        6         0\n",
      "7        7         0\n",
      "8        8         1\n",
      "9        9         0\n",
      "10      10         0\n",
      "11      11         1\n",
      "12      12         1\n",
      "13      13         0\n",
      "14      14         1\n",
      "15      15         0\n",
      "16      16         1\n",
      "17      17         0\n",
      "18      18         1\n",
      "19      19         1\n",
      "20      20         1\n",
      "21      21         0\n",
      "22      22         1\n",
      "23      23         0\n",
      "24      24         0\n",
      "25      25         1\n",
      "26      26         1\n",
      "27      27         1\n",
      "28      28         0\n",
      "29      29         1\n",
      "30      30         1\n",
      "...    ...       ...\n",
      "8971  8971         0\n",
      "8972  8972         0\n",
      "8973  8973         1\n",
      "8974  8974         1\n",
      "8975  8975         0\n",
      "8976  8976         1\n",
      "8977  8977         0\n",
      "8978  8978         1\n",
      "8979  8979         1\n",
      "8980  8980         1\n",
      "8981  8981         1\n",
      "8982  8982         1\n",
      "8983  8983         1\n",
      "8984  8984         0\n",
      "8985  8985         0\n",
      "8986  8986         1\n",
      "8987  8987         1\n",
      "8988  8988         0\n",
      "8989  8989         1\n",
      "8990  8990         0\n",
      "8991  8991         0\n",
      "8992  8992         0\n",
      "8993  8993         0\n",
      "8994  8994         1\n",
      "8995  8995         1\n",
      "8996  8996         0\n",
      "8997  8997         1\n",
      "8998  8998         1\n",
      "8999  8999         0\n",
      "9000  9000         1\n",
      "\n",
      "[9000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "##### FRAMING OUR SOLUTION #####\n",
    "rf_best_pred = pd.DataFrame(rf_best.predict(x_test))\n",
    "rf_best_pred.index += 1\n",
    "rf_best_pred.columns = ['Solution']\n",
    "rf_best_pred['Id'] = np.arange(1,rf_best_pred.shape[0]+1)\n",
    "rf_best_pred = rf_best_pred[['Id', 'Solution']]\n",
    "print(rf_best_pred)\n",
    "\n",
    "#knn_best_pred.to_csv('knn_best_pred.csv')\n",
    "rf_best_pred.to_csv('scikit_submission_rf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
